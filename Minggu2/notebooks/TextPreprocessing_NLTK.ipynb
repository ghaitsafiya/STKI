{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### EKSPERIMEN TEKS PROCESSING MENGGUNAKAN NLTK\n",
        "Melakukan pra-pemrosesan teks (preprocessing) menggunakan library NLTK (Natural Language Toolkit) untuk membersihkan teks sebelum digunakan dalam analisis lanjutan (misalnya klasifikasi sentimen atau deteksi topik)."
      ],
      "metadata": {
        "id": "4Y3kGXlEAR8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalasi Pustaka"
      ],
      "metadata": {
        "id": "7KkUb5aSCgRr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv7_M9Lh-4fM",
        "outputId": "200e3634-9905-40c9-9008-fc1f633fef0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library di Python\n",
        "Pada tahap awal, menyiapkan semua library yang di butuhkan agar proces pembersihan berjalan lancar."
      ],
      "metadata": {
        "id": "tfrsw29mLJZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk #pustaka phyton untuk text mining dan language processing\n",
        "import pandas as pd #untuk membaca dan mengelola data dalam bentuk tabel\n",
        "import string #berisi kumpulan tanda baca yang bisa dihapus dari teks\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')      #mengunduh resource tambahan seperti tokenizer dan daftar stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhyCEtp7CMu9",
        "outputId": "d4815450-0c62-4fae-f06c-5863c59258bf"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Persiapan Dataset\n",
        "Melihat kolom mana yang berisi teks untuk diproses selanjutnya (misalnya pada eksperimen ini adalah kolom \"Tweet\")."
      ],
      "metadata": {
        "id": "af30OdAcLU0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca dataset\n",
        "df = pd.read_csv('Dataset_Sentimen_Emosi.csv') #dataset dibaca dari file .csv dan disimpan dlm variable df\n",
        "print(df.head()) #df.head() menampilkan 5 baris pertama agar tahu struktur kolom dan teksnya"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBATbRVoEWuV",
        "outputId": "713209ee-87be-4005-a411-ce756c951e82"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Tweet  Sentimen  Emosi\n",
            "0  Cegah mata rantai Covid-19,mari kita dirumah s...       1.0      1\n",
            "1  aku mohon yaAllah semoga wabah covid-19 menghi...       1.0     -1\n",
            "2  Pemprov Papua Naikkan Status Jadi Tanggap Daru...       1.0      1\n",
            "3            Covid belum nyampe prigen mbak hmm hoax       0.0     -2\n",
            "4  Nyuruh orang pintar, lu aja Togog. Itu kerumun...      -1.0     -2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pembersihan Text (Cleaning)\n",
        "Menghapus elemen yang tidak relevan agar teks lebih sederhan dan seragam sebelum dianalisis misalnya simbol, angka, dan mengubah huruf menjadi kecil semua."
      ],
      "metadata": {
        "id": "y6igaaGXLc3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()  # ubah ke huruf kecil\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # hapus tanda baca\n",
        "    text = ''.join([i for i in text if not i.isdigit()])  # hapus angka\n",
        "    return text\n",
        "\n",
        "df['clean'] = df['Tweet'].apply(clean_text)\n",
        "print(df[['Tweet', 'clean']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OosjG8mdGw8V",
        "outputId": "d29223f6-513b-4480-959a-e0c5a3a4652a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Tweet  \\\n",
            "0  Cegah mata rantai Covid-19,mari kita dirumah s...   \n",
            "1  aku mohon yaAllah semoga wabah covid-19 menghi...   \n",
            "2  Pemprov Papua Naikkan Status Jadi Tanggap Daru...   \n",
            "3            Covid belum nyampe prigen mbak hmm hoax   \n",
            "4  Nyuruh orang pintar, lu aja Togog. Itu kerumun...   \n",
            "\n",
            "                                               clean  \n",
            "0  cegah mata rantai covidmari kita dirumah saja ...  \n",
            "1  aku mohon yaallah semoga wabah covid menghilan...  \n",
            "2  pemprov papua naikkan status jadi tanggap daru...  \n",
            "3            covid belum nyampe prigen mbak hmm hoax  \n",
            "4  nyuruh orang pintar lu aja togog itu kerumunan...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenisasi\n",
        "Memisahkan kalimat/text menjadi unit-unit kata agar dapat di proses per kata."
      ],
      "metadata": {
        "id": "mypk0E-1MBC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Tokenisasi kalimat\n",
        "df['tokens'] = df['clean'].apply(word_tokenize) #memecah kalimat jadi potongan\" kata (tokens)\n",
        "print(df['tokens'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BndWNW7dJM-E",
        "outputId": "997620a5-eddf-4250-8098-319af14f85b1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    [cegah, mata, rantai, covidmari, kita, dirumah...\n",
            "1    [aku, mohon, yaallah, semoga, wabah, covid, me...\n",
            "2    [pemprov, papua, naikkan, status, jadi, tangga...\n",
            "3      [covid, belum, nyampe, prigen, mbak, hmm, hoax]\n",
            "4    [nyuruh, orang, pintar, lu, aja, togog, itu, k...\n",
            "Name: tokens, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stopword Removal\n",
        "Menghapus kata-kata umum yang tidak mempunya makna penting seperti \"yang\", \"dan\", \"di\", dll"
      ],
      "metadata": {
        "id": "07LaQ_ZRMPEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('indonesian'))  # jika teks Bahasa Indonesia\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    return [word for word in tokens if word not in stop_words]\n",
        "\n",
        "df['filtered'] = df['tokens'].apply(remove_stopwords)\n",
        "print(df[['tokens', 'filtered']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rej8JdQIJhVb",
        "outputId": "894ab13d-1d4a-4c35-e7a0-9b7946a315a3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              tokens  \\\n",
            "0  [cegah, mata, rantai, covidmari, kita, dirumah...   \n",
            "1  [aku, mohon, yaallah, semoga, wabah, covid, me...   \n",
            "2  [pemprov, papua, naikkan, status, jadi, tangga...   \n",
            "3    [covid, belum, nyampe, prigen, mbak, hmm, hoax]   \n",
            "4  [nyuruh, orang, pintar, lu, aja, togog, itu, k...   \n",
            "\n",
            "                                            filtered  \n",
            "0  [cegah, mata, rantai, covidmari, dirumah, minggu]  \n",
            "1  [mohon, yaallah, semoga, wabah, covid, menghil...  \n",
            "2  [pemprov, papua, naikkan, status, tanggap, dar...  \n",
            "3           [covid, nyampe, prigen, mbak, hmm, hoax]  \n",
            "4  [nyuruh, orang, pintar, lu, aja, togog, kerumu...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming (Mengambil Kata Dasar)\n",
        "Menyederhanakan bentuk kata agar model tidak menganggap \"makan\", \"memakan\", dan \"pemakan\" sebagai kata yang berbeda."
      ],
      "metadata": {
        "id": "WQNkrR6tMjb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Sastrawi #library Sastrawi digunakan khusus untuk b.indo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZBpF4a7KNDw",
        "outputId": "92aa159e-7c0f-4f92-f42d-670d0d5f1fb9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Sastrawi in /usr/local/lib/python3.12/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "def stem_text(words):\n",
        "    return [stemmer.stem(word) for word in words]\n",
        "\n",
        "df['stemmed'] = df['filtered'].apply(stem_text)\n",
        "print(df[['filtered', 'stemmed']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR__c6auKQuG",
        "outputId": "b3564325-d2dd-4607-afee-a842e7c5c68c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            filtered  \\\n",
            "0  [cegah, mata, rantai, covidmari, dirumah, minggu]   \n",
            "1  [mohon, yaallah, semoga, wabah, covid, menghil...   \n",
            "2  [pemprov, papua, naikkan, status, tanggap, dar...   \n",
            "3           [covid, nyampe, prigen, mbak, hmm, hoax]   \n",
            "4  [nyuruh, orang, pintar, lu, aja, togog, kerumu...   \n",
            "\n",
            "                                             stemmed  \n",
            "0    [cegah, mata, rantai, covidmari, rumah, minggu]  \n",
            "1  [mohon, yaallah, moga, wabah, covid, hilang, r...  \n",
            "2  [pemprov, papua, naik, status, tanggap, darura...  \n",
            "3           [covid, nyampe, prigen, mbak, hmm, hoax]  \n",
            "4  [nyuruh, orang, pintar, lu, aja, togog, kerumu...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Menggabungkan Kembali Kata Hasil Proses\n",
        "Setelah semua proses, kata-kata hasil steamming digabung kembali menjadi satu kalimat bersih.Menghasilkan teks akhir yang sudah bersih, konsisten, dan siap digunakan dalam TF-IDF atau analisis model."
      ],
      "metadata": {
        "id": "q6lwoBJfM-sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['final_text'] = df['stemmed'].apply(lambda x: ' '.join(x))\n",
        "print(df[['Tweet', 'final_text']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fOKzze5Mq8A",
        "outputId": "e125f5d9-4078-481e-956c-6efd6d04da01"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Tweet  \\\n",
            "0  Cegah mata rantai Covid-19,mari kita dirumah s...   \n",
            "1  aku mohon yaAllah semoga wabah covid-19 menghi...   \n",
            "2  Pemprov Papua Naikkan Status Jadi Tanggap Daru...   \n",
            "3            Covid belum nyampe prigen mbak hmm hoax   \n",
            "4  Nyuruh orang pintar, lu aja Togog. Itu kerumun...   \n",
            "\n",
            "                                          final_text  \n",
            "0           cegah mata rantai covidmari rumah minggu  \n",
            "1     mohon yaallah moga wabah covid hilang ramadhan  \n",
            "2  pemprov papua naik status tanggap darurat covi...  \n",
            "3                  covid nyampe prigen mbak hmm hoax  \n",
            "4  nyuruh orang pintar lu aja togog kerumun orang...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Menyimpan Hasil\n",
        "Simpan hasil preprocessing untuk digunakan pada eksperimen berikutnya (misalnya klasifikasi atau analisis sentimen)."
      ],
      "metadata": {
        "id": "dPbzfHIsNXOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('clean_dataset_nltk.csv', index=False)"
      ],
      "metadata": {
        "id": "8Gu__3JANLYh"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluasi Hasil Preprocessing\n",
        "Melakukan perbandingan teks sebelum dan sesudah preprocessing. Hal ini berfungsi untuk memastikan fungsi cleaning, tokenisasi, dan steamming sudah bekerja sesuai harapan."
      ],
      "metadata": {
        "id": "Obn1P1E_Ni-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    print(f\"Teks Asli     : {df['Tweet'][i]}\")\n",
        "    print(f\"Teks Bersih   : {df['final_text'][i]}\")\n",
        "    print('-'*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp7f-d6NNt0z",
        "outputId": "af18a538-b039-4ea8-9e5d-3bf4a6b2bb86"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks Asli     : Cegah mata rantai Covid-19,mari kita dirumah saja hingga hari Minggu.....\n",
            "Teks Bersih   : cegah mata rantai covidmari rumah minggu\n",
            "--------------------------------------------------\n",
            "Teks Asli     : aku mohon yaAllah semoga wabah covid-19 menghilang sebelum ramadhan datang \n",
            "Teks Bersih   : mohon yaallah moga wabah covid hilang ramadhan\n",
            "--------------------------------------------------\n",
            "Teks Asli     : Pemprov Papua Naikkan Status Jadi Tanggap Darurat Covid-19. OPM\n",
            "Teks Bersih   : pemprov papua naik status tanggap darurat covid opm\n",
            "--------------------------------------------------\n",
            "Teks Asli     : Covid belum nyampe prigen mbak hmm hoax\n",
            "Teks Bersih   : covid nyampe prigen mbak hmm hoax\n",
            "--------------------------------------------------\n",
            "Teks Asli     : Nyuruh orang pintar, lu aja Togog. Itu kerumunan orang bisa nularin covid 19 lol. Mikir !!!!\n",
            "Teks Bersih   : nyuruh orang pintar lu aja togog kerumun orang nularin covid lol mikir\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}